{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "problema sugli embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including required python libraries used in this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, SimpleRNN,LSTM, Activation\n",
    "from keras.utils import np_utils\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading train emoji and test emoji data which are attached in the repo\n",
    "train = pd.read_json(os.path.join(fileDir, r'data_input/evalita_test.json'),orient=\"records\", lines=True, nrows=15)\n",
    "test = pd.read_json(os.path.join(fileDir, r'data_input/evalita_train.json'),orient=\"records\", lines=True,nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'red_heart': '‚ù§Ô∏è', 'face_with_tears_of_joy': 'üòÇ', 'smiling_face_with_heart_eyes': 'üòç', 'winking_face': 'üòâ', 'smiling_face_with_smiling_eyes': 'üòä', 'beaming_face_with_smiling_eyes': 'üòÅ', 'grinning_face': 'üòÄ', 'face_blowing_a_kiss': 'üòò', 'smiling_face_with_sunglasses': 'üòé', 'thumbs_up': 'üëç', 'rolling_on_the_floor_laughing': 'ü§£', 'thinking_face': 'ü§î', 'blue_heart': 'üíô', 'winking_face_with_tongue': 'üòú', 'face_screaming_in_fear': 'üò±', 'flexed_biceps': 'üí™', 'face_savoring_food': 'üòã', 'grinning_face_with_sweat': 'üòÖ', 'loudly_crying_face': 'üò≠', 'TOP_arrow': 'üîù', 'two_hearts': 'üíï', 'sun': '‚òÄÔ∏è', 'kiss_mark': 'üíã', 'sparkles': '‚ú®', 'rose': 'üåπ'}\n"
     ]
    }
   ],
   "source": [
    "txt_to_emoji = {}\n",
    "idx_to_emoji = {}\n",
    "file_txt = os.path.join(fileDir, r\"utils/txt_2_emoji.json\")\n",
    "file_idx = os.path.join(fileDir, r\"utils/idx_2_emoji.json\")\n",
    "with open(file_txt,\"r\",encoding=\"utf-8\") as f:\n",
    "    txt_to_emoji = json.load(f)\n",
    "with open(file_idx,\"r\",encoding=\"utf-8\") as f:\n",
    "    idx_to_emoji = json.load(f)\n",
    "emoji_to_idx = {}\n",
    "emoji_to_idx = {value : key for (key, value) in idx_to_emoji.items()}\n",
    "print(txt_to_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_no_emoji</th>\n",
       "      <th>uid</th>\n",
       "      <th>ground_truth_label</th>\n",
       "      <th>tid</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@eallora6 io desideravo il meglio e ho sposato...</td>\n",
       "      <td>227841404</td>\n",
       "      <td>winking_face</td>\n",
       "      <td>ITAMOJI_test_1</td>\n",
       "      <td>2015-08-18 23:46:16+00:00</td>\n",
       "      <td>633787023699148800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#mascoloaformentera \\nBen sticazzi ahaha sei i...</td>\n",
       "      <td>3429936850</td>\n",
       "      <td>winking_face</td>\n",
       "      <td>ITAMOJI_test_2</td>\n",
       "      <td>2017-08-03 21:45:16+00:00</td>\n",
       "      <td>893226284242874368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@GLPini @sscnapoli Non ha torto. La squadra di...</td>\n",
       "      <td>2294138965</td>\n",
       "      <td>winking_face</td>\n",
       "      <td>ITAMOJI_test_3</td>\n",
       "      <td>2018-01-22 07:51:03+00:00</td>\n",
       "      <td>955347059078500352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Su' questo hai ragione https://t.co/qfDawgI2Y9</td>\n",
       "      <td>395361626</td>\n",
       "      <td>winking_face</td>\n",
       "      <td>ITAMOJI_test_4</td>\n",
       "      <td>2017-12-19 16:39:07+00:00</td>\n",
       "      <td>943158765574066176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Visita archeologica...!!! @ Colosseo https://t...</td>\n",
       "      <td>856817140715880448</td>\n",
       "      <td>winking_face</td>\n",
       "      <td>ITAMOJI_test_5</td>\n",
       "      <td>2017-09-14 13:11:01+00:00</td>\n",
       "      <td>908317161541664768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_no_emoji                 uid  \\\n",
       "0  @eallora6 io desideravo il meglio e ho sposato...           227841404   \n",
       "1  #mascoloaformentera \\nBen sticazzi ahaha sei i...          3429936850   \n",
       "2  @GLPini @sscnapoli Non ha torto. La squadra di...          2294138965   \n",
       "3     Su' questo hai ragione https://t.co/qfDawgI2Y9           395361626   \n",
       "4  Visita archeologica...!!! @ Colosseo https://t...  856817140715880448   \n",
       "\n",
       "  ground_truth_label             tid                created_at  \\\n",
       "0       winking_face  ITAMOJI_test_1 2015-08-18 23:46:16+00:00   \n",
       "1       winking_face  ITAMOJI_test_2 2017-08-03 21:45:16+00:00   \n",
       "2       winking_face  ITAMOJI_test_3 2018-01-22 07:51:03+00:00   \n",
       "3       winking_face  ITAMOJI_test_4 2017-12-19 16:39:07+00:00   \n",
       "4       winking_face  ITAMOJI_test_5 2017-09-14 13:11:01+00:00   \n",
       "\n",
       "             tweet_id  \n",
       "0  633787023699148800  \n",
       "1  893226284242874368  \n",
       "2  955347059078500352  \n",
       "3  943158765574066176  \n",
       "4  908317161541664768  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking data by showing first 5 rows of the train data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>uid</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text_no_emoji</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>622416920701054976</td>\n",
       "      <td>3115912511</td>\n",
       "      <td>2015-07-18 14:45:32+00:00</td>\n",
       "      <td>#Noiaaa#goro#aspettandolasera @ Porto di Goro ...</td>\n",
       "      <td>red_heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>737712884965363712</td>\n",
       "      <td>423498157</td>\n",
       "      <td>2016-05-31 18:30:32+00:00</td>\n",
       "      <td>e niente, nonostante i casini e gli impegni di...</td>\n",
       "      <td>red_heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>671023999057567744</td>\n",
       "      <td>488427533</td>\n",
       "      <td>2015-11-29 17:52:43+00:00</td>\n",
       "      <td>#Faccebuffe #friends #friendship #saturdaynigh...</td>\n",
       "      <td>red_heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>650002923393548288</td>\n",
       "      <td>3041411470</td>\n",
       "      <td>2015-10-02 17:42:28+00:00</td>\n",
       "      <td>Un nuovo post √® ora online su http://t.co/h6pK...</td>\n",
       "      <td>red_heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>628245096694202368</td>\n",
       "      <td>1693227686</td>\n",
       "      <td>2015-08-03 16:44:37+00:00</td>\n",
       "      <td>@vogliosoloriker video e magari iscriverti?Ho ...</td>\n",
       "      <td>red_heart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tid         uid                created_at  \\\n",
       "0  622416920701054976  3115912511 2015-07-18 14:45:32+00:00   \n",
       "1  737712884965363712   423498157 2016-05-31 18:30:32+00:00   \n",
       "2  671023999057567744   488427533 2015-11-29 17:52:43+00:00   \n",
       "3  650002923393548288  3041411470 2015-10-02 17:42:28+00:00   \n",
       "4  628245096694202368  1693227686 2015-08-03 16:44:37+00:00   \n",
       "\n",
       "                                       text_no_emoji      label  \n",
       "0  #Noiaaa#goro#aspettandolasera @ Porto di Goro ...  red_heart  \n",
       "1  e niente, nonostante i casini e gli impegni di...  red_heart  \n",
       "2  #Faccebuffe #friends #friendship #saturdaynigh...  red_heart  \n",
       "3  Un nuovo post √® ora online su http://t.co/h6pK...  red_heart  \n",
       "4  @vogliosoloriker video e magari iscriverti?Ho ...  red_heart  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking data by showing first 5 rows of the test data\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo un dizionario con tutte le emoji presenti nel training set e aggiungo una colonna 'key_emoji'\n",
    "train.rename({\"ground_truth_label\":\"label\"}, axis=1, inplace=True)\n",
    "train['key_emoji'] = train['label'].map(txt_to_emoji).map(emoji_to_idx)\n",
    "test['key_emoji'] = test['label'].map(txt_to_emoji).map(emoji_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_no_emoji</th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "      <th>tid</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>key_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@eallora6 io desideravo il meglio e ho sposato...</td>\n",
       "      <td>227841404</td>\n",
       "      <td>winking_face</td>\n",
       "      <td>ITAMOJI_test_1</td>\n",
       "      <td>2015-08-18 23:46:16+00:00</td>\n",
       "      <td>633787023699148800</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#mascoloaformentera \\nBen sticazzi ahaha sei i...</td>\n",
       "      <td>3429936850</td>\n",
       "      <td>winking_face</td>\n",
       "      <td>ITAMOJI_test_2</td>\n",
       "      <td>2017-08-03 21:45:16+00:00</td>\n",
       "      <td>893226284242874368</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@GLPini @sscnapoli Non ha torto. La squadra di...</td>\n",
       "      <td>2294138965</td>\n",
       "      <td>winking_face</td>\n",
       "      <td>ITAMOJI_test_3</td>\n",
       "      <td>2018-01-22 07:51:03+00:00</td>\n",
       "      <td>955347059078500352</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Su' questo hai ragione https://t.co/qfDawgI2Y9</td>\n",
       "      <td>395361626</td>\n",
       "      <td>winking_face</td>\n",
       "      <td>ITAMOJI_test_4</td>\n",
       "      <td>2017-12-19 16:39:07+00:00</td>\n",
       "      <td>943158765574066176</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Visita archeologica...!!! @ Colosseo https://t...</td>\n",
       "      <td>856817140715880448</td>\n",
       "      <td>winking_face</td>\n",
       "      <td>ITAMOJI_test_5</td>\n",
       "      <td>2017-09-14 13:11:01+00:00</td>\n",
       "      <td>908317161541664768</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_no_emoji                 uid  \\\n",
       "0  @eallora6 io desideravo il meglio e ho sposato...           227841404   \n",
       "1  #mascoloaformentera \\nBen sticazzi ahaha sei i...          3429936850   \n",
       "2  @GLPini @sscnapoli Non ha torto. La squadra di...          2294138965   \n",
       "3     Su' questo hai ragione https://t.co/qfDawgI2Y9           395361626   \n",
       "4  Visita archeologica...!!! @ Colosseo https://t...  856817140715880448   \n",
       "\n",
       "          label             tid                created_at            tweet_id  \\\n",
       "0  winking_face  ITAMOJI_test_1 2015-08-18 23:46:16+00:00  633787023699148800   \n",
       "1  winking_face  ITAMOJI_test_2 2017-08-03 21:45:16+00:00  893226284242874368   \n",
       "2  winking_face  ITAMOJI_test_3 2018-01-22 07:51:03+00:00  955347059078500352   \n",
       "3  winking_face  ITAMOJI_test_4 2017-12-19 16:39:07+00:00  943158765574066176   \n",
       "4  winking_face  ITAMOJI_test_5 2017-09-14 13:11:01+00:00  908317161541664768   \n",
       "\n",
       "  key_emoji  \n",
       "0         3  \n",
       "1         3  \n",
       "2         3  \n",
       "3         3  \n",
       "4         3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>uid</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text_no_emoji</th>\n",
       "      <th>label</th>\n",
       "      <th>key_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>622416920701054976</td>\n",
       "      <td>3115912511</td>\n",
       "      <td>2015-07-18 14:45:32+00:00</td>\n",
       "      <td>#Noiaaa#goro#aspettandolasera @ Porto di Goro ...</td>\n",
       "      <td>red_heart</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>737712884965363712</td>\n",
       "      <td>423498157</td>\n",
       "      <td>2016-05-31 18:30:32+00:00</td>\n",
       "      <td>e niente, nonostante i casini e gli impegni di...</td>\n",
       "      <td>red_heart</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>671023999057567744</td>\n",
       "      <td>488427533</td>\n",
       "      <td>2015-11-29 17:52:43+00:00</td>\n",
       "      <td>#Faccebuffe #friends #friendship #saturdaynigh...</td>\n",
       "      <td>red_heart</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>650002923393548288</td>\n",
       "      <td>3041411470</td>\n",
       "      <td>2015-10-02 17:42:28+00:00</td>\n",
       "      <td>Un nuovo post √® ora online su http://t.co/h6pK...</td>\n",
       "      <td>red_heart</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>628245096694202368</td>\n",
       "      <td>1693227686</td>\n",
       "      <td>2015-08-03 16:44:37+00:00</td>\n",
       "      <td>@vogliosoloriker video e magari iscriverti?Ho ...</td>\n",
       "      <td>red_heart</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tid         uid                created_at  \\\n",
       "0  622416920701054976  3115912511 2015-07-18 14:45:32+00:00   \n",
       "1  737712884965363712   423498157 2016-05-31 18:30:32+00:00   \n",
       "2  671023999057567744   488427533 2015-11-29 17:52:43+00:00   \n",
       "3  650002923393548288  3041411470 2015-10-02 17:42:28+00:00   \n",
       "4  628245096694202368  1693227686 2015-08-03 16:44:37+00:00   \n",
       "\n",
       "                                       text_no_emoji      label key_emoji  \n",
       "0  #Noiaaa#goro#aspettandolasera @ Porto di Goro ...  red_heart         0  \n",
       "1  e niente, nonostante i casini e gli impegni di...  red_heart         0  \n",
       "2  #Faccebuffe #friends #friendship #saturdaynigh...  red_heart         0  \n",
       "3  Un nuovo post √® ora online su http://t.co/h6pK...  red_heart         0  \n",
       "4  @vogliosoloriker video e magari iscriverti?Ho ...  red_heart         0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ‚ù§Ô∏è\n",
      "1 üòÇ\n",
      "2 üòç\n",
      "3 üòâ\n",
      "4 üòä\n",
      "5 üòÅ\n",
      "6 üòÄ\n",
      "7 üòò\n",
      "8 üòé\n",
      "9 üëç\n",
      "10 ü§£\n",
      "11 ü§î\n",
      "12 üíô\n",
      "13 üòú\n",
      "14 üò±\n",
      "15 üí™\n",
      "16 üòã\n",
      "17 üòÖ\n",
      "18 üò≠\n",
      "19 üîù\n",
      "20 üíï\n",
      "21 ‚òÄÔ∏è\n",
      "22 üíã\n",
      "23 ‚ú®\n",
      "24 üåπ\n"
     ]
    }
   ],
   "source": [
    "# Printing each emoji icon by emojizing each emoji\n",
    "for (emoji,ix) in emoji_to_idx.items():\n",
    "    print (ix,end=\" \")\n",
    "    print (emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15,) (15,) (10,) (10,)\n",
      "-------------------------\n",
      "@eallora6 io desideravo il meglio e ho sposato il peggio 3\n"
     ]
    }
   ],
   "source": [
    "# Creating training and testing data\n",
    "X_train = train['text_no_emoji']\n",
    "Y_train = train['key_emoji']\n",
    "\n",
    "X_test = test['text_no_emoji']\n",
    "Y_test = test['key_emoji']\n",
    "\n",
    "print (X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "print (\"-------------------------\")\n",
    "print (X_train[0],Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-7fb8399e9b6d>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[ix] = X_train[ix].split()\n",
      "<ipython-input-15-7fb8399e9b6d>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[ix] = X_test[ix].split()\n"
     ]
    }
   ],
   "source": [
    "# Splitting the train data from sentences to words\n",
    "for ix in range(X_train.shape[0]):\n",
    "    X_train[ix] = X_train[ix].split()\n",
    "\n",
    "# Splitting the test data from sentences to words\n",
    "for ix in range(X_test.shape[0]):\n",
    "    X_test[ix] = X_test[ix].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels into categorical form\n",
    "Y_train = np_utils.to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@eallora6', 'io', 'desideravo', 'il', 'meglio', 'e', 'ho', 'sposato', 'il', 'peggio'] [0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Now checking the above conversion by printing train and test data at 0th index\n",
    "print (X_train[0],Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4,  5,  7,  8,  9, 10, 11, 13, 18, 20, 25]),\n",
       " array([1, 3, 1, 1, 1, 2, 2, 1, 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check maximum length of sentence in training data\n",
    "np.unique(np.array([len(ix) for ix in X_train]) , return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6,  9, 10, 11, 13, 14, 17, 18, 19, 24]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check maximum length of senetence in testing data\n",
    "np.unique(np.array([len(ix) for ix in X_test]) , return_counts=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Creating  embeddings dictionary with key = word and value = list of words in glove vector\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open(r'D:\\Marco\\Universita\\3ANNO\\Tesi\\emoji-prediction\\glove.6B.50d.txt', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings in italiano\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'it_vectors_wiki_lg' (1.0.1) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\spacy\\_ml.py:287: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (962148, 300))\n",
      "  warnings.warn(Warnings.W020.format(shape=vectors.data.shape))\n"
     ]
    }
   ],
   "source": [
    "f = spacy.load('it_vectors_wiki_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2593208677638477497 ,\n",
      "926329778511176045 di\n",
      "12646065887601541794 .\n",
      "1720370409040345145 e\n",
      "15884554869126768810 \"\n",
      "8081183868394845856 il\n",
      "6804705863737483857 la\n",
      "3002984154512732771 in\n",
      "11901859001352538922 a\n",
      "14178434899903659559 del\n",
      "13130769157622138839 che\n",
      "2776894843003769526 √®\n",
      "12188161997964598936 un\n",
      "16213571876086197332 della\n",
      "799935474406865112 per\n",
      "3842344029291005339 )\n",
      "12638816674900267446 (\n",
      "6945313634251781056 con\n",
      "1019041181156623609 una\n",
      "15791954665091178185 nel\n",
      "17784187696877778905 da\n",
      "13884469947995795204 si\n",
      "5097672513440128799 i\n",
      "9153284864653046197 -\n",
      "8222700718889469974 al\n",
      "13361843836202591494 le\n",
      "4524258024941853120 Il\n",
      "4626582094216806925 dei\n",
      "6239908149323985340 La\n",
      "16488435112747374027 alla\n",
      "11532473245541075862 :\n",
      "5307304325359566725 come\n",
      "15888754967501154131 non\n",
      "7681984841348307237 nella\n",
      "1145194667254797146 delle\n",
      "13220287238529672498 pi√π\n",
      "470538875325686083 dal\n",
      "15768381024286549287 sono\n",
      "14699363847199467374 anche\n",
      "8521863001484601166 ha\n",
      "434727375527117087 fu\n",
      "2684585717478260826 ad\n",
      "4602649588396751778 gli\n",
      "7933676983478586786 Nel\n",
      "7785346724220822594 sua\n",
      "11179282889058780238 ed\n",
      "631425121691394544 ;\n",
      "17858175945452170869 suo\n",
      "7352634781387649911 dalla\n",
      "3766551886407196655 due\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for key in f.vocab.vectors.keys():\n",
    "    i+=1\n",
    "    print(key, f.vocab.strings[key])\n",
    "    if i==50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "for key,vector in f.vocab.vectors.items():\n",
    "    word = f.vocab.strings[key]\n",
    "    embeddings_index[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking length of a particular word\n",
    "embeddings_index[\"io\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37135571241378784"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "# Checking cosine similarity of words happy and sad\n",
    "spatial.distance.cosine(embeddings_index[\"felice\"], embeddings_index[\"triste\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30207496881484985"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking cosine similarity of words India and Delhi\n",
    "spatial.distance.cosine(embeddings_index[\"gatto\"], embeddings_index[\"cane\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852149011567235"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking cosine similarity of words france and paris\n",
    "spatial.distance.cosine(embeddings_index[\"francia\"], embeddings_index[\"parigi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trovo la lunghezza massima di X_train\n",
    "max =0\n",
    "for x in X_train:\n",
    "    if len(x) > max:\n",
    "        max=len(x)\n",
    "maxTest = 0\n",
    "for x in X_test:\n",
    "    if len(x) > maxTest:\n",
    "        maxTest = len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the embedding matrix\n",
    "embedding_matrix_train = np.zeros((X_train.shape[0], max, 300))\n",
    "embedding_matrix_test = np.zeros((X_test.shape[0], maxTest, 300))\n",
    "\n",
    "#se la parola del training set o test set non √® presente nell'embeddings da errore...\n",
    "for ix in range(X_train.shape[0]):\n",
    "    for ij in range(len(X_train[ix])):\n",
    "        try:\n",
    "            embedding_matrix_train[ix][ij] = embeddings_index[X_train[ix][ij].lower()]\n",
    "        except KeyError: #danno problemi gli utenti @..., ma non posso lasciare il campo a 0\n",
    "            pass\n",
    "for ix in range(X_test.shape[0]):\n",
    "    for ij in range(len(X_test[ix])):\n",
    "        try:\n",
    "            embedding_matrix_test[ix][ij] = embeddings_index[X_test[ix][ij].lower()]\n",
    "        except KeyError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 25, 300) (10, 24, 300)\n"
     ]
    }
   ],
   "source": [
    "print (embedding_matrix_train.shape, embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 10, 64)            7360      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 15,941\n",
      "Trainable params: 15,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# A simple RNN network to classify the emoji class from an input Sentence\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(SimpleRNN(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Loss and Optimiser for the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:224 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer sequential: expected shape=(None, None, 50), found shape=[None, 25, 300]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-edd879a27bcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Training of the model and Setting hyperparameters for the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m hist = model.fit(embedding_matrix_train,Y_train,\n\u001b[0m\u001b[0;32m      3\u001b[0m                 \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 )\n",
      "\u001b[1;32m~\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\Users\\marco\\.conda\\envs\\emoji-prediction\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:224 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer sequential: expected shape=(None, None, 50), found shape=[None, 25, 300]\n"
     ]
    }
   ],
   "source": [
    "# Training of the model and Setting hyperparameters for the model\n",
    "hist = model.fit(embedding_matrix_train,Y_train,\n",
    "                epochs = 50, batch_size=32,shuffle=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of the trained model \n",
    "pred = model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy of the algorithm\n",
    "float(sum(pred==Y_test))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing the sentences with the predicted and labled emoji\n",
    "for ix in range(embedding_matrix_test.shape[0]):\n",
    "    \n",
    "    if pred[ix] != Y_test[ix]:\n",
    "        print(ix)\n",
    "        print (test[0][ix],end=\" \")\n",
    "        print (idx_to_emoji[pred[ix]],end=\" \")\n",
    "        print (idx_to_emoji[Y_test[ix]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for our random sentence\n",
    "x = ['io', 'penso', 'che','questa', 'classe', 'sia', 'davvero', 'interessante!']\n",
    "\n",
    "x_ = np.zeros((1,10,50))\n",
    "\n",
    "for ix in range(len(x)):\n",
    "    x_[0][ix] = embeddings_index[x[ix].lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  - Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(10,50), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Loss ,Optimiser for model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training model\n",
    "hist = model.fit(embedding_matrix_train,Y_train,\n",
    "                epochs = 50, batch_size=32,shuffle=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of trained model\n",
    "pred = model.predict_classes(embedding_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating accuracy / score  of the model\n",
    "float(sum(pred==Y_test))/embedding_matrix_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing the sentences with the predicted and the labelled emoji\n",
    "for ix in range(embedding_matrix_test.shape[0]):\n",
    "    \n",
    "    if pred[ix] != Y_test[ix]:\n",
    "        print(ix)\n",
    "        print (test[0][ix],end=\" \")\n",
    "        print (idx_to_emoji[pred[ix]],end=\" \")\n",
    "        print (idx_to_emoji[Y_test[ix]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
